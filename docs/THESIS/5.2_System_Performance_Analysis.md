## 5.2 System Performance Analysis

This section evaluates end‑to‑end throughput and latency under increasing concurrent user load for the on‑premise stack (Ollama + quantized GGUF SLMs) against a cloud baseline (via LiteLLM). The benchmark was executed on a VM labeled `vm` with approximately 49.3 GB RAM and 7 vCPUs (GPU details were not captured in this run’s `system-info.json`; see `results/runs/20250913_223907_vm/throughput/system-info.json`).

Methodology and metrics
- **workload**: short interactive prompt (length ≈ 13), `max_tokens=128`, `temperature=0.0` (Azure is forced to `1.0` by its API). Each (model × concurrency) includes one warm‑up request that is not counted in the summary.
- **experiment design**: 160 requests per repetition × 3 repetitions = 480 attempts per point. This provides ~24 samples in the top 5% tail, making p95 stable.
- **concurrency vector**: 1, 2, 4, 8, 16. A doubling sweep reveals the “knee” where scaling flattens. It also maps to the expected user load (5–10 users ≈ near the `c=8` point) and tests burst headroom at `c=16`.
- **definitions**:
  - **Throughput (RPS)**: successful requests per second across all repetitions.
  - **Tokens/s (TPS)**: total output tokens per second; useful when completion lengths vary.
  - **Latency mean/p50/p95**: per‑request end‑to‑end time measured from request to response; aggregated across repetitions.
  - **Tail ratio**: `p95 / mean latency`; a simple indicator of tail heaviness.
- **reliability**: the harness retries 5× with exponential backoff on 429/5xx; failures after backoff are counted as errors; latency stats include only successful requests.
- **figures** (generated by the run):
  - `../../results/runs/20250913_223907_vm/throughput/charts/provider_rps_vs_concurrency.png`
  - `../../results/runs/20250913_223907_vm/throughput/charts/models_rps_vs_concurrency.png`
  - `../../results/runs/20250913_223907_vm/throughput/charts/provider_latency_p95_vs_concurrency.png`
  - `../../results/runs/20250913_223907_vm/throughput/charts/models_latency_p95_vs_concurrency.png`
  - Tail‑ratio counterparts for both provider and models


### 5.2.1 Throughput (Requests Per Second)

Throughput measures how many requests the system completes per second under a fixed number of simultaneous in‑flight requests.

Key findings (RPS vs concurrency)
- **On‑prem SLMs scale to a knee at c≈4–8; the fastest model saturates near that point.**
  - Qwen2.5‑3B (Q4_K_M, Ollama):
    - c=1: ~8.15 RPS; c=2: ~15.23; c=4: ~20.95; c=8: ~21.02; c=16: ~20.76
    - Plateau ≈21 RPS at c=8–16.
  - Llama‑3.2‑3B and Falcon3‑3B (Q4_K_M, Ollama):
    - Peak ≈9.5–9.8 RPS around c=4–8; little gain beyond c=4.
  - Phi‑3.5‑mini and Phi‑3/4‑mini (Ollama):
    - Peak ≈2–4 RPS and largely flat with concurrency; these models are throughput‑limited on this node.
- **Cloud baseline (via LiteLLM) scales with concurrency, but absolute RPS is lower on this short‑prompt workload.**
  - Azure GPT‑5: c=16 → ~7.24 RPS (steady increases with c).
  - Claude Opus 4.1: c=16 → ~5.41 RPS.
  - Gemini 2.5 Pro: c=16 → ~2.66 RPS, with 47 errors (433/480 successes), indicating provider‑side queuing/backoff at high concurrency.
- **Interpretation**: With very short prompts and capped completions, on‑prem SLMs avoid network/provider overhead and can achieve higher raw RPS per node, up to the model/hardware knee. Cloud endpoints add network hops and provider scheduling; they favor elasticity and consistency over peak single‑node RPS.

Why 160 requests × 3 repetitions?
- **p95 stability**: 480 samples per point provide ~24 tail datapoints (top 5%), which stabilizes p95.
- **variance smoothing**: 3 repetitions reduce the influence of outliers or transient warm‑ups.

Why 1–16 concurrency?
- **practical mapping**: `c=8` closely represents a target of 5–10 concurrent users; `c=16` probes burst headroom and tail behavior.
- **doubling sweep**: 1, 2, 4, 8, 16 efficiently reveals the knee without excessive runs.

Implications for capacity planning (5–10 concurrent users)
- With Qwen2.5‑3B, a single node sustained ≈21 RPS at `c=8` with sub‑second latency (see 5.2.2). This comfortably covers 5–10 concurrent users for short responses.
- If production prompts/completions are longer, re‑run with representative content; RPS will decrease and TPS becomes the more comparable throughput metric across models/providers.

Figures
- Figure 5.9: Provider Throughput (RPS) vs. Concurrency — `../../results/runs/20250913_223907_vm/throughput/charts/provider_rps_vs_concurrency.png`
- Figure 5.10: Model Throughput (RPS) vs. Concurrency — `../../results/runs/20250913_223907_vm/throughput/charts/models_rps_vs_concurrency.png`


### 5.2.2 Latency (p95)

p95 reflects tail latency—what a slower 1 in 20 user experiences—and is critical for perceived responsiveness.

Key findings (p95 vs concurrency)
- **On‑prem SLMs (fastest tier) maintain sub‑second p95 up to c≈8–16.**
  - Qwen2.5‑3B (Ollama):
    - c=4: p95 ≈ 0.203 s; c=8: ≈ 0.389 s; c=16: ≈ 0.772 s.
    - Tail ratio (p95/mean) ≈ 1.05 at c=8–16 (very tight tails).
  - Llama‑3.2‑3B, Falcon3‑3B:
    - p95 grows with concurrency but remains near‑linear with mean; tail ratio ≈1.05–1.1 at c=16 (predictable spread).
  - Phi family:
    - p95 climbs sharply with concurrency (e.g., Phi‑4‑mini c=16 p95 ≈ 7.73 s). These models are latency‑sensitive to load; avoid them for multi‑user responsiveness.
- **Cloud endpoints show higher absolute p95 but relatively stable scaling.**
  - Azure GPT‑5: p95 ≈ 3.66 s (c=1) → ≈ 3.14 s (c=16).
  - Claude Opus 4.1: p95 ≈ 3.46 s (c=1) → ≈ 4.87 s (c=16).
  - Gemini 2.5 Pro: p95 ≈ 3.25 s (c=1) → ≈ 4.33 s (c=16), with some errors at high c.
  - Tail ratio typically ≈1.6–1.8 at higher c, reflecting heavier tails from network/provider queuing.
- **Rule‑of‑thumb check (Little’s Law)**: `RPS ≈ concurrency ÷ mean_latency`. Example (Qwen2.5‑3B at c=8): `8 / 0.373 ≈ 21.4` RPS vs measured ≈21.0 RPS—consistent with a lightly queued system near the knee.

Implications for experience at 5–10 concurrent users
- **On‑prem (fast SLM choice)**: Expect sub‑second p95 at `c≈8` with tight tails; excellent interactive UX.
- **Cloud**: Higher p95 (≈3–5 s), but more resilience and uniformity under higher concurrency if scaled horizontally by the provider. Suitable for consistent SLOs across spikes, at the cost of per‑request latency.

Notes and caveats
- **workload sensitivity**: Results use a very short prompt and capped output. For production flows (likely longer prompts/completions or RAG), re‑run in `--mode rag` with your real testset for representative p95/TPS.
- **error behavior under load**: Only Gemini showed non‑zero errors at `c=16` (47/480), likely rate‑limit or transient 5xx despite backoff. This is visible in the CSV `errors` column.
- **reproducibility**: Raw CSV at `../../results/runs/20250913_223907_vm/throughput/benchmark-results.csv`. Figures in `../../results/runs/20250913_223907_vm/throughput/charts/`.

Figures
- Figure 5.11: Provider p95 Latency vs. Concurrency — `../../results/runs/20250913_223907_vm/throughput/charts/provider_latency_p95_vs_concurrency.png`
- Figure 5.12: Model p95 Latency vs. Concurrency — `../../results/runs/20250913_223907_vm/throughput/charts/models_latency_p95_vs_concurrency.png`
